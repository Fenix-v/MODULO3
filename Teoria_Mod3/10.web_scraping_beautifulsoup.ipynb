{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c7690cd",
   "metadata": {},
   "source": [
    "## Web Scraping con bs4 (BeautifulSoup)\n",
    "\n",
    "**`BeautifulSoup`** es una biblioteca de python para extraer contenido de ficheros **`HTML`** y **`XML`**.\n",
    "\n",
    "```sh\n",
    "pip install beautifulsoup4\n",
    "```\n",
    "\n",
    "Primero usamos **`requests`** para tener acceso al contenido **`HTML`** de las páginas web, luego usamos **`BeautifulSoup`** para extraer la información de ese conteido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cf30de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import bs4 # Para ver la versión\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eda550-0a98-45ee-a723-a63896e5ed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versiones\n",
    "\n",
    "print(f\"numpy=={np.__version__}\")\n",
    "print(f\"requests=={requests.__version__}\")\n",
    "print(f\"bs4=={bs4.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb539d32",
   "metadata": {},
   "source": [
    "### requests\n",
    "\n",
    "**`requests.get()`** toma un **`url`** (o enlace) y retorna la **\"respuesta\"** del servidor. Este nuevo objeto también extrae el código **`HTML`** del **`url`**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0600e80b",
   "metadata": {},
   "source": [
    "Cada **\"request\"** toma un tiempo de respuesta, por lo que si intentamos hacer muchos **\"request\"** en un plazo corto de tiempo nuestro I.P. será baneado de la página web para evitar que colapse por el gran número de **\"requests\"**. En el peor de los casos la página recibirá tantos **\"requests\"** que colapsará y la dejaremos fuera de servicio.\n",
    "\n",
    "El **`CAPTCHA`** es una herramienta que utilizan las páginas web para evitar el **web scraping** o evitar que un mismo usuario usando bots colapse la página.\n",
    "\n",
    "_**\"Completely Automated Public Turing test to tell Computers and Humans Apart\"**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e3e36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://google.com/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "print(response)\n",
    "\n",
    "print(bool(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278dcb75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# El atributo .text retorna el HTML de la página \n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd9ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c7cb4c",
   "metadata": {},
   "source": [
    "### BeautifulSoup\n",
    "\n",
    "Si la respuesta del **`requests`** es positiva podemos pasar este objeto **`requests.get()`** a **`BeautifulSoup`** para que nos ayude a filtrar la información y extraerla más fácil. \n",
    "\n",
    "Los métodos más comunes de **`BeautifulSoup`** son:\n",
    "\n",
    "|Método           |Descripción                                                                                        |\n",
    "|-----------------|---------------------------------------------------------------------------------------------------|\n",
    "|**`.body`**      | Retorna el contenido dentro de la etiqueta **`body`**.                                            |\n",
    "|**`.title`**     | Retorna el titulo del **HTML**.                                                                   |\n",
    "|**`.find()`**    | Busca en el **HTML** y retorna la primera ocurrencia del filtro en un objeto **`bs4`**.           |\n",
    "|**`.find_all()`**| Busca en el **HTML** y retorna todas las ocurrencias del filtro en una lista de objetos **`bs4`**.|\n",
    "|**`.text`**      | Retorna el contenido de un objeto **`bs4`** en un **`str`**.                                          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da58052",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f9b238",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77030637",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620410a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensacine\n",
    "\n",
    "url = \"https://www.sensacine.com/peliculas/en-cartelera/cines/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b0f2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0bc1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896d26c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto retorna un objeto bs4\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef9358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con .text lo convertimos a str\n",
    "\n",
    "soup.title.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df212d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup.title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e311dae",
   "metadata": {},
   "source": [
    "### Filtros con bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaa6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar la primera etiqueta h2\n",
    "\n",
    "soup.find(\"h2\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f0ddaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Con .find_all() encontramos todas las etiquetas y nos retorna una lista con objetos bs4\n",
    "\n",
    "soup.find_all(\"h2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6535a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encuentra la primera etiqueta a\n",
    "\n",
    "soup.find(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0464c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encuentra todas las etiquetas a\n",
    "\n",
    "soup.find_all(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4ea01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(soup.find_all(\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628eaf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos encadenar filtros siempre que nos retorne un objeto bs4\n",
    "\n",
    "soup.find(\"h2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c582e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(\"h2\").find(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9abb9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(\"h2\").find(\"a\")[\"href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5fca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(\"h2\").find(\"a\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be2903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(\"h2\").find(\"a\")[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a8e9f6",
   "metadata": {},
   "source": [
    "Cuando veamos una etiqueta con **class** en ella podemos usarla para hacer un filtro más específico.\n",
    "```html\n",
    "<li class=\"mdl\">\n",
    "```\n",
    "\n",
    "Como en Python **`class`** es una palabra reservada, debemos usar **`class_`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea74eda2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup.find(\"li\", class_ = \"mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf00a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(\"li\", class_ = \"mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24f3397",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(\"span\", class_ = \"stareval-note\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a1fe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(\"span\", class_ = \"stareval-note\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a133304",
   "metadata": {},
   "source": [
    "Otra forma de usar estos filtros de **`bs4`** es atraves del parametro **`attrs`** de un diccionario.\n",
    "\n",
    "Este diccionario tendrá como llave el nombre de las etiquetas y como valor el valor asociado a esa etiqueta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3437d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicc_bs4 = {\"class\" : \"stareval-note\"}\n",
    "\n",
    "soup.find(\"span\", attrs = dicc_bs4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6ce966",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(\"span\", attrs = dicc_bs4).text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b3d14b",
   "metadata": {},
   "source": [
    "Utilizando bucles podemos iterar sobre los **`.find_all()`** y sacar información de forma automatizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8381dd96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# En la etiqueta h3 tenemos el url y el titulo de la pelicula\n",
    "\n",
    "soup.find_all(\"h2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aef7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(\"h2\").find(\"a\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e55366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos = list()\n",
    "\n",
    "urls = list()\n",
    "\n",
    "for bs in soup.find_all(\"h2\"):\n",
    "    \n",
    "    try:\n",
    "        titulo = bs.find(\"a\").text\n",
    "    except:\n",
    "        titulo = np.nan\n",
    "        \n",
    "    try:\n",
    "        url = bs.find(\"a\")[\"href\"]\n",
    "    except:\n",
    "        url = np.nan\n",
    "    \n",
    "    titulos.append(titulo)\n",
    "    urls.append(url)\n",
    "    \n",
    "    \n",
    "for t, u in zip(titulos, urls):\n",
    "    print(t, u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3699a764",
   "metadata": {},
   "source": [
    "Toda esta información se puede agrupar en un DataFrame y convertir a **`.csv`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c9a6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39f0062",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df[\"titulo\"] = titulos\n",
    "\n",
    "df[\"urls\"] = urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c54bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6c8703",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"urls\"] = df[\"urls\"].apply(lambda x : f\"https://www.sensacine.com{x}\" if type(x) == str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949c1eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4704af72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_or_buf = Nombre del archivo terminado en .csv\n",
    "# index = False para que no se guarde el indice como nueva columna en el csv\n",
    "# sep = \",\" para que el separador sea \",\", se puede cambiar por cualquier otro separador.\n",
    "\n",
    "df.to_csv(path_or_buf = \"sensacine.csv\", index = False, sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa457f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(path = \"sensacine.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9881539",
   "metadata": {},
   "source": [
    "### Agregar al DataFrame la duración de cada pelicula y su puntaje:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4c7e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(\"div\", class_ = \"meta-body-item meta-body-info\").text.replace(\"\\n\", \"\").split(\"/\")#[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9131c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [np.nan if len(x.text.replace(\"\\n\", \"\").split(\"/\")) < 3 else x.text.replace(\"\\n\", \"\").split(\"/\")[1] for x in soup.find_all(\"div\", class_ = \"meta-body-item meta-body-info\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a7cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_duraciones = list()\n",
    "\n",
    "for x in soup.find_all(\"div\", class_ = \"meta-body-item meta-body-info\"):\n",
    "    \n",
    "    x = x.text.replace(\"\\n\", \"\").split(\"/\")\n",
    "    \n",
    "    if len(x) < 3:\n",
    "        \n",
    "        lista_duraciones.append(np.nan)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        lista_duraciones.append(x[1])\n",
    "        \n",
    "lista_duraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203246df",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(\"li\", class_ = \"mdl\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7270e20f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup.find_all(\"li\", class_ = \"mdl\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f948dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(soup.find_all(\"li\", class_ = \"mdl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bd89cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_puntaciones = list()\n",
    "\n",
    "for pelicula in soup.find_all(\"li\", class_ = \"mdl\"):\n",
    "    \n",
    "    if pelicula.find(\"a\") != None:\n",
    "    \n",
    "        try:\n",
    "            x = float(pelicula.find(\"div\", class_ = \"rating-item\").find(\"span\", class_ = \"stareval-note\").text.replace(\",\", \".\"))\n",
    "\n",
    "        except:\n",
    "\n",
    "            x = np.nan\n",
    "    \n",
    "        lista_puntaciones.append(x)\n",
    "        \n",
    "lista_puntaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21345cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"duracion\"] = lista_duraciones\n",
    "\n",
    "df[\"puntuacion\"] = lista_puntaciones\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782569bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17a665b",
   "metadata": {},
   "source": [
    "### Información de 1 pelicula:\n",
    "\n",
    "Vamos a entrar al primer **`url`** y sacar toda su información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb45c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.sensacine.com/peliculas/pelicula-246641/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618df1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titulo\n",
    "\n",
    "soup.find(\"div\", class_ = \"titlebar titlebar-page\").text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969a1127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fecha\n",
    "\n",
    "dict_bs4 = {\"class\" : \"meta-body-item meta-body-info\"}\n",
    "\n",
    "soup.find(\"div\", attrs = dict_bs4).text.strip().split(\"\\n\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117045ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duración\n",
    "\n",
    "dict_bs4 = {\"class\" : \"meta-body-item meta-body-info\"}\n",
    "\n",
    "soup.find(\"div\", attrs = dict_bs4).text.replace(\"\\n\", \"\").split(\"/\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2012796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guion \n",
    "\n",
    "soup.find_all(\"div\", class_ = \"meta-body-item meta-body-direction\")[1].find_all(\"span\")[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574f456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reparto \n",
    "\n",
    "soup.find(\"div\", class_ = \"meta-body-item meta-body-actor\").find_all(\"span\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e67fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.text for x in soup.find(\"div\", class_ = \"meta-body-item meta-body-actor\").find_all(\"span\")[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125d9012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Géneros\n",
    "\n",
    "dict_bs4 = {\"class\" : \"meta-body-item meta-body-info\"}\n",
    "\n",
    "soup.find(\"div\", attrs = dict_bs4).text.replace(\"\\n\", \"\").split(\"/\")[-1].split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7d22cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinopsis\n",
    "\n",
    "soup.find(\"section\", attrs = {\"class\" : \"section ovw ovw-synopsis\"}).find(\"div\", class_ = \"content-txt\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91884a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665d6369",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"urls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dc462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame\n",
    "\n",
    "titulos = list()\n",
    "fechas = list()\n",
    "duraciones = list()\n",
    "guiones = list()\n",
    "repartos = list()\n",
    "generos = list()\n",
    "sinopsises = list()\n",
    "\n",
    "for url in df[\"urls\"]:\n",
    "    \n",
    "    print(url)\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        titulo = soup.find(\"div\", class_ = \"titlebar titlebar-page\").text\n",
    "        fecha = soup.find(\"div\", attrs = dict_bs4).text.strip().split(\"\\n\")[0]\n",
    "        duracion = soup.find(\"div\", class_ = \"meta-body-item meta-body-info\").text.replace(\"\\n\", \"\").split(\"/\")[1]\n",
    "        guion = soup.find_all(\"div\", class_ = \"meta-body-item meta-body-direction\")[1].find_all(\"span\")[1].text\n",
    "        reparto = \", \".join([x.text for x in soup.find(\"div\", class_ = \"meta-body-item meta-body-actor\").find_all(\"span\")[1:]])\n",
    "        genero = \" \".join(soup.find(\"div\", class_ = \"meta-body-item meta-body-info\").text.replace(\"\\n\", \"\").split(\"/\")[-1].split(\",\"))\n",
    "        sinopsis = soup.find(\"section\", class_ = \"section ovw ovw-synopsis\").find(\"div\", class_ = \"content-txt\").text\n",
    "\n",
    "        titulos.append(titulo)\n",
    "        fechas.append(fecha)\n",
    "        duraciones.append(duracion)\n",
    "        guiones.append(guion)\n",
    "        repartos.append(reparto)\n",
    "        generos.append(genero)\n",
    "        sinopsises.append(sinopsis)\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        titulos.append(np.nan)\n",
    "        fechas.append(np.nan)\n",
    "        duraciones.append(np.nan)\n",
    "        guiones.append(np.nan)\n",
    "        repartos.append(np.nan)\n",
    "        generos.append(np.nan)\n",
    "        sinopsises.append(np.nan)\n",
    "    \n",
    "    sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9ed22c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24c7c832",
   "metadata": {},
   "source": [
    "Muchas veces sucede que no todas las páginas tienen la misma información, por lo que tenemos que asegurarnos de que si no existe un dato lo sustituimos con un np.nan. Por eso podemos usar:\n",
    "```python\n",
    "try:\n",
    "    \n",
    "except:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352d926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame\n",
    "\n",
    "titulos = list()\n",
    "fechas = list()\n",
    "duraciones = list()\n",
    "guiones = list()\n",
    "repartos = list()\n",
    "generos = list()\n",
    "sinopsises = list()\n",
    "\n",
    "for url in df[\"urls\"]:\n",
    "    \n",
    "    print(url)\n",
    "    \n",
    "    if type(url) == str:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "#### Titulo #######################################################################################################   \n",
    "\n",
    "        try:\n",
    "            titulo = soup.find(\"div\", class_ = \"titlebar titlebar-page\").text\n",
    "\n",
    "        except:\n",
    "            titulo = np.nan\n",
    "        \n",
    "#### Fecha ########################################################################################################   \n",
    "\n",
    "        try:\n",
    "            fecha = soup.find(\"div\", class_ = \"meta-body-item meta-body-info\").text.strip().split(\"\\n\")[0]\n",
    "\n",
    "        except:\n",
    "            fecha = np.nan\n",
    "\n",
    "#### Duracion #####################################################################################################\n",
    "\n",
    "        try:\n",
    "            duracion = soup.find(\"div\", attrs = dict_bs4).text.replace(\"\\n\", \"\").split(\"/\")[1]\n",
    "\n",
    "        except:\n",
    "            duracion = np.nan\n",
    "\n",
    "#### Guion ########################################################################################################\n",
    "\n",
    "        try:\n",
    "            guion = soup.find_all(\"div\", class_ = \"meta-body-item meta-body-direction\")[1].find_all(\"span\")[1].text\n",
    "\n",
    "        except:\n",
    "            guion = np.nan\n",
    "\n",
    "#### Reparto ######################################################################################################\n",
    "\n",
    "        try:\n",
    "            reparto = \", \".join([x.text for x in soup.find(\"div\", class_ = \"meta-body-item meta-body-actor\").find_all(\"span\")[1:]])\n",
    "\n",
    "        except:\n",
    "            reparto = np.nan\n",
    "\n",
    "#### Genero #######################################################################################################\n",
    "\n",
    "        try:\n",
    "            genero = \" \".join(soup.find(\"div\", attrs = dict_bs4).text.replace(\"\\n\", \"\").split(\"/\")[-1].split(\",\"))\n",
    "\n",
    "        except:\n",
    "            genero = np.nan\n",
    "\n",
    "#### Sinopsis #####################################################################################################\n",
    "\n",
    "        try:\n",
    "            sinopsis = soup.find(\"section\", attrs = {\"class\" : \"section ovw ovw-synopsis\"}).find(\"div\", class_ = \"content-txt\").text\n",
    "\n",
    "        except:\n",
    "            sinopsis = np.nan\n",
    "        \n",
    "##################################################################################################################\n",
    "\n",
    "        # appends\n",
    "    \n",
    "        titulos.append(titulo)\n",
    "        fechas.append(fecha)\n",
    "        duraciones.append(duracion)\n",
    "        guiones.append(guion)\n",
    "        repartos.append(reparto)\n",
    "        generos.append(genero)\n",
    "        sinopsises.append(sinopsis)\n",
    "\n",
    "        sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed14af17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peliculas = pd.DataFrame()\n",
    "\n",
    "df_peliculas[\"titulo\"] = titulos\n",
    "df_peliculas[\"fecha\"] = fechas\n",
    "df_peliculas[\"duracion\"] = duraciones\n",
    "df_peliculas[\"guion\"] = guiones\n",
    "df_peliculas[\"reparto\"] = repartos\n",
    "df_peliculas[\"genero\"] = generos\n",
    "df_peliculas[\"sinopsis\"] = sinopsises\n",
    "\n",
    "df_peliculas[\"url\"] = df[\"urls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce077f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peliculas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33200003",
   "metadata": {},
   "source": [
    "### Ejercicio: Modificar el código para que no hayan errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133aa13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame\n",
    "\n",
    "titulos = list()\n",
    "fechas = list()\n",
    "duraciones = list()\n",
    "guiones = list()\n",
    "repartos = list()\n",
    "generos = list()\n",
    "sinopsises = list()\n",
    "\n",
    "for url in df[\"urls\"]:\n",
    "    \n",
    "    print(url)\n",
    "    \n",
    "    \n",
    "    if type(url) == str:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "#### Titulo #######################################################################################################   \n",
    "\n",
    "        try:\n",
    "            titulo = soup.find(\"div\", class_ = \"titlebar titlebar-page\").text\n",
    "\n",
    "        except:\n",
    "            titulo = np.nan\n",
    "        \n",
    "#### Fecha ########################################################################################################   \n",
    "\n",
    "        try:\n",
    "            fecha = soup.find(\"div\", class_ = \"meta-body-item meta-body-info\").text.strip().split(\"\\n\")[0]\n",
    "\n",
    "        except:\n",
    "            fecha = np.nan\n",
    "\n",
    "#### Duracion #####################################################################################################\n",
    "\n",
    "        try:\n",
    "            duracion = soup.find(\"div\", attrs = dict_bs4).text.replace(\"\\n\", \"\").split(\"/\")\n",
    "\n",
    "            if len(duracion) < 3:\n",
    "\n",
    "                duracion = np.nan\n",
    "\n",
    "            else:\n",
    "\n",
    "                duracion = duracion[1]\n",
    "\n",
    "        except:\n",
    "            duracion = np.nan\n",
    "\n",
    "#### Guion ########################################################################################################\n",
    "\n",
    "        try:\n",
    "            guion = soup.find_all(\"div\", class_ = \"meta-body-item meta-body-direction\")[1].find_all(\"span\")[1].text\n",
    "\n",
    "        except:\n",
    "            guion = np.nan\n",
    "\n",
    "#### Reparto ######################################################################################################\n",
    "\n",
    "        try:\n",
    "            reparto = \", \".join([x.text for x in soup.find(\"div\", class_ = \"meta-body-item meta-body-actor\").find_all(\"span\")[1:]])\n",
    "\n",
    "        except:\n",
    "            reparto = np.nan\n",
    "\n",
    "#### Genero #######################################################################################################\n",
    "\n",
    "        try:\n",
    "            genero = \" \".join(soup.find(\"div\", attrs = dict_bs4).text.replace(\"\\n\", \"\").split(\"/\")[-1].split(\",\"))\n",
    "\n",
    "        except:\n",
    "            genero = np.nan\n",
    "\n",
    "#### Sinopsis #####################################################################################################\n",
    "\n",
    "        try:\n",
    "            sinopsis = soup.find(\"section\", attrs = {\"class\" : \"section ovw ovw-synopsis\"}).find(\"div\", class_ = \"content-txt\").text\n",
    "\n",
    "        except:\n",
    "            sinopsis = np.nan\n",
    "        \n",
    "##################################################################################################################\n",
    "\n",
    "        # appends\n",
    "\n",
    "        titulos.append(titulo)\n",
    "        fechas.append(fecha)\n",
    "        duraciones.append(duracion)\n",
    "        guiones.append(guion)\n",
    "        repartos.append(reparto)\n",
    "        generos.append(genero)\n",
    "        sinopsises.append(sinopsis)\n",
    "\n",
    "        sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d7832",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peliculas = pd.DataFrame()\n",
    "\n",
    "df_peliculas[\"titulo\"] = titulos\n",
    "df_peliculas[\"fecha\"] = fechas\n",
    "df_peliculas[\"duracion\"] = duraciones\n",
    "df_peliculas[\"guion\"] = guiones\n",
    "df_peliculas[\"reparto\"] = repartos\n",
    "df_peliculas[\"genero\"] = generos\n",
    "df_peliculas[\"sinopsis\"] = sinopsises\n",
    "\n",
    "df_peliculas[\"url\"] = df[\"urls\"]\n",
    "df_peliculas[\"puntuacion\"] = df[\"puntuacion\"]\n",
    "\n",
    "df_peliculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3b80a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peliculas.to_csv(\"info_peliculas.csv\", index = False, sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b839973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
