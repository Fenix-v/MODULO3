{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c7690cd",
   "metadata": {},
   "source": [
    "## Web Scraping con bs4 (BeautifulSoup)\n",
    "\n",
    "**`BeautifulSoup`** es una biblioteca de python para extraer contenido de ficheros **`HTML`** y **`XML`**.\n",
    "\n",
    "```sh\n",
    "pip install beautifulsoup4\n",
    "```\n",
    "\n",
    "Primero usamos **`requests`** para tener acceso al contenido **`HTML`** de las páginas web, luego usamos **`BeautifulSoup`** para extraer la información de ese conteido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "379acf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.3 soupsieve-2.6\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2cf30de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import bs4 # Para ver la versión\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59eda550-0a98-45ee-a723-a63896e5ed98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy==2.2.0\n",
      "requests==2.32.3\n",
      "bs4==4.12.3\n"
     ]
    }
   ],
   "source": [
    "# Versiones\n",
    "\n",
    "print(f\"numpy=={np.__version__}\")\n",
    "print(f\"requests=={requests.__version__}\")\n",
    "print(f\"bs4=={bs4.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb539d32",
   "metadata": {},
   "source": [
    "### requests\n",
    "\n",
    "**`requests.get()`** toma un **`url`** (o enlace) y retorna la **\"respuesta\"** del servidor. Este nuevo objeto también extrae el código **`HTML`** del **`url`**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0600e80b",
   "metadata": {},
   "source": [
    "Cada **\"request\"** toma un tiempo de respuesta, por lo que si intentamos hacer muchos **\"request\"** en un plazo corto de tiempo nuestro I.P. será baneado de la página web para evitar que colapse por el gran número de **\"requests\"**. En el peor de los casos la página recibirá tantos **\"requests\"** que colapsará y la dejaremos fuera de servicio.\n",
    "\n",
    "El **`CAPTCHA`** es una herramienta que utilizan las páginas web para evitar el **web scraping** o evitar que un mismo usuario usando bots colapse la página.\n",
    "\n",
    "_**\"Completely Automated Public Turing test to tell Computers and Humans Apart\"**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e3e36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://google.com/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "print(response)\n",
    "\n",
    "print(bool(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278dcb75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# El atributo .text retorna el HTML de la página \n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd9ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c7cb4c",
   "metadata": {},
   "source": [
    "### BeautifulSoup\n",
    "\n",
    "Si la respuesta del **`requests`** es positiva podemos pasar este objeto **`requests.get()`** a **`BeautifulSoup`** para que nos ayude a filtrar la información y extraerla más fácil. \n",
    "\n",
    "Los métodos más comunes de **`BeautifulSoup`** son:\n",
    "\n",
    "|Método           |Descripción                                                                                        |\n",
    "|-----------------|---------------------------------------------------------------------------------------------------|\n",
    "|**`.body`**      | Retorna el contenido dentro de la etiqueta **`body`**.                                            |\n",
    "|**`.title`**     | Retorna el titulo del **HTML**.                                                                   |\n",
    "|**`.find()`**    | Busca en el **HTML** y retorna la primera ocurrencia del filtro en un objeto **`bs4`**.           |\n",
    "|**`.find_all()`**| Busca en el **HTML** y retorna todas las ocurrencias del filtro en una lista de objetos **`bs4`**.|\n",
    "|**`.text`**      | Retorna el contenido de un objeto **`bs4`** en un **`str`**.                                          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da58052",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f9b238",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77030637",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620410a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensacine\n",
    "\n",
    "url = \"https://www.sensacine.com/peliculas/en-cartelera/cines/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b0f2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0bc1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896d26c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto retorna un objeto bs4\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef9358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con .text lo convertimos a str\n",
    "\n",
    "soup.title.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df212d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup.title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e311dae",
   "metadata": {},
   "source": [
    "### Filtros con bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaa6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar la primera etiqueta h2\n",
    "\n",
    "soup.find(\"h2\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f0ddaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Con .find_all() encontramos todas las etiquetas y nos retorna una lista con objetos bs4\n",
    "\n",
    "soup.find_all(\"h2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6535a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encuentra la primera etiqueta a\n",
    "\n",
    "soup.find(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0464c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encuentra todas las etiquetas a\n",
    "\n",
    "soup.find_all(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4ea01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(soup.find_all(\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628eaf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos encadenar filtros siempre que nos retorne un objeto bs4\n",
    "\n",
    "soup.find(\"h2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c582e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(\"h2\").find(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9abb9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(\"h2\").find(\"a\")[\"href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5fca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(\"h2\").find(\"a\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be2903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(\"h2\").find(\"a\")[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a8e9f6",
   "metadata": {},
   "source": [
    "Cuando veamos una etiqueta con **class** en ella podemos usarla para hacer un filtro más específico.\n",
    "```html\n",
    "<li class=\"mdl\">\n",
    "```\n",
    "\n",
    "Como en Python **`class`** es una palabra reservada, debemos usar **`class_`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea74eda2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup.find(\"li\", class_ = \"mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf00a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(\"li\", class_ = \"mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24f3397",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(\"span\", class_ = \"stareval-note\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a1fe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(\"span\", class_ = \"stareval-note\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a133304",
   "metadata": {},
   "source": [
    "Otra forma de usar estos filtros de **`bs4`** es atraves del parametro **`attrs`** de un diccionario.\n",
    "\n",
    "Este diccionario tendrá como llave el nombre de las etiquetas y como valor el valor asociado a esa etiqueta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3437d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicc_bs4 = {\"class\" : \"stareval-note\"}\n",
    "\n",
    "soup.find(\"span\", attrs = dicc_bs4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6ce966",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(\"span\", attrs = dicc_bs4).text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b3d14b",
   "metadata": {},
   "source": [
    "Utilizando bucles podemos iterar sobre los **`.find_all()`** y sacar información de forma automatizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8381dd96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# En la etiqueta h3 tenemos el url y el titulo de la pelicula\n",
    "\n",
    "soup.find_all(\"h2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aef7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(\"h2\").find(\"a\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e55366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos = list()\n",
    "\n",
    "urls = list()\n",
    "\n",
    "for bs in soup.find_all(\"h2\"):\n",
    "    \n",
    "    try:\n",
    "        titulo = bs.find(\"a\").text\n",
    "    except:\n",
    "        titulo = np.nan\n",
    "        \n",
    "    try:\n",
    "        url = bs.find(\"a\")[\"href\"]\n",
    "    except:\n",
    "        url = np.nan\n",
    "    \n",
    "    titulos.append(titulo)\n",
    "    urls.append(url)\n",
    "    \n",
    "    \n",
    "for t, u in zip(titulos, urls):\n",
    "    print(t, u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3699a764",
   "metadata": {},
   "source": [
    "Toda esta información se puede agrupar en un DataFrame y convertir a **`.csv`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c9a6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39f0062",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df[\"titulo\"] = titulos\n",
    "\n",
    "df[\"urls\"] = urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c54bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6c8703",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"urls\"] = df[\"urls\"].apply(lambda x : f\"https://www.sensacine.com{x}\" if type(x) == str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949c1eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4704af72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_or_buf = Nombre del archivo terminado en .csv\n",
    "# index = False para que no se guarde el indice como nueva columna en el csv\n",
    "# sep = \",\" para que el separador sea \",\", se puede cambiar por cualquier otro separador.\n",
    "\n",
    "df.to_csv(path_or_buf = \"sensacine.csv\", index = False, sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa457f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(path = \"sensacine.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9881539",
   "metadata": {},
   "source": [
    "### Agregar al DataFrame la duración de cada pelicula y su puntaje:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4c7e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(\"div\", class_ = \"meta-body-item meta-body-info\").text.replace(\"\\n\", \"\").split(\"/\")#[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9131c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [np.nan if len(x.text.replace(\"\\n\", \"\").split(\"/\")) < 3 else x.text.replace(\"\\n\", \"\").split(\"/\")[1] for x in soup.find_all(\"div\", class_ = \"meta-body-item meta-body-info\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a7cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_duraciones = list()\n",
    "\n",
    "for x in soup.find_all(\"div\", class_ = \"meta-body-item meta-body-info\"):\n",
    "    \n",
    "    x = x.text.replace(\"\\n\", \"\").split(\"/\")\n",
    "    \n",
    "    if len(x) < 3:\n",
    "        \n",
    "        lista_duraciones.append(np.nan)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        lista_duraciones.append(x[1])\n",
    "        \n",
    "lista_duraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203246df",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(\"li\", class_ = \"mdl\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7270e20f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup.find_all(\"li\", class_ = \"mdl\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f948dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(soup.find_all(\"li\", class_ = \"mdl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bd89cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_puntaciones = list()\n",
    "\n",
    "for pelicula in soup.find_all(\"li\", class_ = \"mdl\"):\n",
    "    \n",
    "    if pelicula.find(\"a\") != None:\n",
    "    \n",
    "        try:\n",
    "            x = float(pelicula.find(\"div\", class_ = \"rating-item\").find(\"span\", class_ = \"stareval-note\").text.replace(\",\", \".\"))\n",
    "\n",
    "        except:\n",
    "\n",
    "            x = np.nan\n",
    "    \n",
    "        lista_puntaciones.append(x)\n",
    "        \n",
    "lista_puntaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21345cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"duracion\"] = lista_duraciones\n",
    "\n",
    "df[\"puntuacion\"] = lista_puntaciones\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782569bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17a665b",
   "metadata": {},
   "source": [
    "### Información de 1 pelicula:\n",
    "\n",
    "Vamos a entrar al primer **`url`** y sacar toda su información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb45c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.sensacine.com/peliculas/pelicula-246641/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618df1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titulo\n",
    "\n",
    "soup.find(\"div\", class_ = \"titlebar titlebar-page\").text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969a1127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fecha\n",
    "\n",
    "dict_bs4 = {\"class\" : \"meta-body-item meta-body-info\"}\n",
    "\n",
    "soup.find(\"div\", attrs = dict_bs4).text.strip().split(\"\\n\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117045ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duración\n",
    "\n",
    "dict_bs4 = {\"class\" : \"meta-body-item meta-body-info\"}\n",
    "\n",
    "soup.find(\"div\", attrs = dict_bs4).text.replace(\"\\n\", \"\").split(\"/\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2012796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guion \n",
    "\n",
    "soup.find_all(\"div\", class_ = \"meta-body-item meta-body-direction\")[1].find_all(\"span\")[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574f456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reparto \n",
    "\n",
    "soup.find(\"div\", class_ = \"meta-body-item meta-body-actor\").find_all(\"span\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e67fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.text for x in soup.find(\"div\", class_ = \"meta-body-item meta-body-actor\").find_all(\"span\")[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125d9012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Géneros\n",
    "\n",
    "dict_bs4 = {\"class\" : \"meta-body-item meta-body-info\"}\n",
    "\n",
    "soup.find(\"div\", attrs = dict_bs4).text.replace(\"\\n\", \"\").split(\"/\")[-1].split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7d22cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinopsis\n",
    "\n",
    "soup.find(\"section\", attrs = {\"class\" : \"section ovw ovw-synopsis\"}).find(\"div\", class_ = \"content-txt\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91884a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665d6369",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"urls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dc462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame\n",
    "\n",
    "titulos = list()\n",
    "fechas = list()\n",
    "duraciones = list()\n",
    "guiones = list()\n",
    "repartos = list()\n",
    "generos = list()\n",
    "sinopsises = list()\n",
    "\n",
    "for url in df[\"urls\"]:\n",
    "    \n",
    "    print(url)\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        titulo = soup.find(\"div\", class_ = \"titlebar titlebar-page\").text\n",
    "        fecha = soup.find(\"div\", attrs = dict_bs4).text.strip().split(\"\\n\")[0]\n",
    "        duracion = soup.find(\"div\", class_ = \"meta-body-item meta-body-info\").text.replace(\"\\n\", \"\").split(\"/\")[1]\n",
    "        guion = soup.find_all(\"div\", class_ = \"meta-body-item meta-body-direction\")[1].find_all(\"span\")[1].text\n",
    "        reparto = \", \".join([x.text for x in soup.find(\"div\", class_ = \"meta-body-item meta-body-actor\").find_all(\"span\")[1:]])\n",
    "        genero = \" \".join(soup.find(\"div\", class_ = \"meta-body-item meta-body-info\").text.replace(\"\\n\", \"\").split(\"/\")[-1].split(\",\"))\n",
    "        sinopsis = soup.find(\"section\", class_ = \"section ovw ovw-synopsis\").find(\"div\", class_ = \"content-txt\").text\n",
    "\n",
    "        titulos.append(titulo)\n",
    "        fechas.append(fecha)\n",
    "        duraciones.append(duracion)\n",
    "        guiones.append(guion)\n",
    "        repartos.append(reparto)\n",
    "        generos.append(genero)\n",
    "        sinopsises.append(sinopsis)\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        titulos.append(np.nan)\n",
    "        fechas.append(np.nan)\n",
    "        duraciones.append(np.nan)\n",
    "        guiones.append(np.nan)\n",
    "        repartos.append(np.nan)\n",
    "        generos.append(np.nan)\n",
    "        sinopsises.append(np.nan)\n",
    "    \n",
    "    sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9ed22c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24c7c832",
   "metadata": {},
   "source": [
    "Muchas veces sucede que no todas las páginas tienen la misma información, por lo que tenemos que asegurarnos de que si no existe un dato lo sustituimos con un np.nan. Por eso podemos usar:\n",
    "```python\n",
    "try:\n",
    "    \n",
    "except:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352d926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame\n",
    "\n",
    "titulos = list()\n",
    "fechas = list()\n",
    "duraciones = list()\n",
    "guiones = list()\n",
    "repartos = list()\n",
    "generos = list()\n",
    "sinopsises = list()\n",
    "\n",
    "for url in df[\"urls\"]:\n",
    "    \n",
    "    print(url)\n",
    "    \n",
    "    if type(url) == str:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "#### Titulo #######################################################################################################   \n",
    "\n",
    "        try:\n",
    "            titulo = soup.find(\"div\", class_ = \"titlebar titlebar-page\").text\n",
    "\n",
    "        except:\n",
    "            titulo = np.nan\n",
    "        \n",
    "#### Fecha ########################################################################################################   \n",
    "\n",
    "        try:\n",
    "            fecha = soup.find(\"div\", class_ = \"meta-body-item meta-body-info\").text.strip().split(\"\\n\")[0]\n",
    "\n",
    "        except:\n",
    "            fecha = np.nan\n",
    "\n",
    "#### Duracion #####################################################################################################\n",
    "\n",
    "        try:\n",
    "            duracion = soup.find(\"div\", attrs = dict_bs4).text.replace(\"\\n\", \"\").split(\"/\")[1]\n",
    "\n",
    "        except:\n",
    "            duracion = np.nan\n",
    "\n",
    "#### Guion ########################################################################################################\n",
    "\n",
    "        try:\n",
    "            guion = soup.find_all(\"div\", class_ = \"meta-body-item meta-body-direction\")[1].find_all(\"span\")[1].text\n",
    "\n",
    "        except:\n",
    "            guion = np.nan\n",
    "\n",
    "#### Reparto ######################################################################################################\n",
    "\n",
    "        try:\n",
    "            reparto = \", \".join([x.text for x in soup.find(\"div\", class_ = \"meta-body-item meta-body-actor\").find_all(\"span\")[1:]])\n",
    "\n",
    "        except:\n",
    "            reparto = np.nan\n",
    "\n",
    "#### Genero #######################################################################################################\n",
    "\n",
    "        try:\n",
    "            genero = \" \".join(soup.find(\"div\", attrs = dict_bs4).text.replace(\"\\n\", \"\").split(\"/\")[-1].split(\",\"))\n",
    "\n",
    "        except:\n",
    "            genero = np.nan\n",
    "\n",
    "#### Sinopsis #####################################################################################################\n",
    "\n",
    "        try:\n",
    "            sinopsis = soup.find(\"section\", attrs = {\"class\" : \"section ovw ovw-synopsis\"}).find(\"div\", class_ = \"content-txt\").text\n",
    "\n",
    "        except:\n",
    "            sinopsis = np.nan\n",
    "        \n",
    "##################################################################################################################\n",
    "\n",
    "        # appends\n",
    "    \n",
    "        titulos.append(titulo)\n",
    "        fechas.append(fecha)\n",
    "        duraciones.append(duracion)\n",
    "        guiones.append(guion)\n",
    "        repartos.append(reparto)\n",
    "        generos.append(genero)\n",
    "        sinopsises.append(sinopsis)\n",
    "\n",
    "        sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed14af17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peliculas = pd.DataFrame()\n",
    "\n",
    "df_peliculas[\"titulo\"] = titulos\n",
    "df_peliculas[\"fecha\"] = fechas\n",
    "df_peliculas[\"duracion\"] = duraciones\n",
    "df_peliculas[\"guion\"] = guiones\n",
    "df_peliculas[\"reparto\"] = repartos\n",
    "df_peliculas[\"genero\"] = generos\n",
    "df_peliculas[\"sinopsis\"] = sinopsises\n",
    "\n",
    "df_peliculas[\"url\"] = df[\"urls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce077f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peliculas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33200003",
   "metadata": {},
   "source": [
    "### Ejercicio: Modificar el código para que no hayan errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133aa13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame\n",
    "\n",
    "titulos = list()\n",
    "fechas = list()\n",
    "duraciones = list()\n",
    "guiones = list()\n",
    "repartos = list()\n",
    "generos = list()\n",
    "sinopsises = list()\n",
    "\n",
    "for url in df[\"urls\"]:\n",
    "    \n",
    "    print(url)\n",
    "    \n",
    "    \n",
    "    if type(url) == str:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "#### Titulo #######################################################################################################   \n",
    "\n",
    "        try:\n",
    "            titulo = soup.find(\"div\", class_ = \"titlebar titlebar-page\").text\n",
    "\n",
    "        except:\n",
    "            titulo = np.nan\n",
    "        \n",
    "#### Fecha ########################################################################################################   \n",
    "\n",
    "        try:\n",
    "            fecha = soup.find(\"div\", class_ = \"meta-body-item meta-body-info\").text.strip().split(\"\\n\")[0]\n",
    "\n",
    "        except:\n",
    "            fecha = np.nan\n",
    "\n",
    "#### Duracion #####################################################################################################\n",
    "\n",
    "        try:\n",
    "            duracion = soup.find(\"div\", attrs = dict_bs4).text.replace(\"\\n\", \"\").split(\"/\")\n",
    "\n",
    "            if len(duracion) < 3:\n",
    "\n",
    "                duracion = np.nan\n",
    "\n",
    "            else:\n",
    "\n",
    "                duracion = duracion[1]\n",
    "\n",
    "        except:\n",
    "            duracion = np.nan\n",
    "\n",
    "#### Guion ########################################################################################################\n",
    "\n",
    "        try:\n",
    "            guion = soup.find_all(\"div\", class_ = \"meta-body-item meta-body-direction\")[1].find_all(\"span\")[1].text\n",
    "\n",
    "        except:\n",
    "            guion = np.nan\n",
    "\n",
    "#### Reparto ######################################################################################################\n",
    "\n",
    "        try:\n",
    "            reparto = \", \".join([x.text for x in soup.find(\"div\", class_ = \"meta-body-item meta-body-actor\").find_all(\"span\")[1:]])\n",
    "\n",
    "        except:\n",
    "            reparto = np.nan\n",
    "\n",
    "#### Genero #######################################################################################################\n",
    "\n",
    "        try:\n",
    "            genero = \" \".join(soup.find(\"div\", attrs = dict_bs4).text.replace(\"\\n\", \"\").split(\"/\")[-1].split(\",\"))\n",
    "\n",
    "        except:\n",
    "            genero = np.nan\n",
    "\n",
    "#### Sinopsis #####################################################################################################\n",
    "\n",
    "        try:\n",
    "            sinopsis = soup.find(\"section\", attrs = {\"class\" : \"section ovw ovw-synopsis\"}).find(\"div\", class_ = \"content-txt\").text\n",
    "\n",
    "        except:\n",
    "            sinopsis = np.nan\n",
    "        \n",
    "##################################################################################################################\n",
    "\n",
    "        # appends\n",
    "\n",
    "        titulos.append(titulo)\n",
    "        fechas.append(fecha)\n",
    "        duraciones.append(duracion)\n",
    "        guiones.append(guion)\n",
    "        repartos.append(reparto)\n",
    "        generos.append(genero)\n",
    "        sinopsises.append(sinopsis)\n",
    "\n",
    "        sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d7832",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peliculas = pd.DataFrame()\n",
    "\n",
    "df_peliculas[\"titulo\"] = titulos\n",
    "df_peliculas[\"fecha\"] = fechas\n",
    "df_peliculas[\"duracion\"] = duraciones\n",
    "df_peliculas[\"guion\"] = guiones\n",
    "df_peliculas[\"reparto\"] = repartos\n",
    "df_peliculas[\"genero\"] = generos\n",
    "df_peliculas[\"sinopsis\"] = sinopsises\n",
    "\n",
    "df_peliculas[\"url\"] = df[\"urls\"]\n",
    "df_peliculas[\"puntuacion\"] = df[\"puntuacion\"]\n",
    "\n",
    "df_peliculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3b80a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peliculas.to_csv(\"info_peliculas.csv\", index = False, sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b839973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
